# Modify the script to run in one shot on lambda labs

import os 
import math
from argparse import ArgumentParser
from typing import Dict, List, Any

import numpy as np
import torch
from datasets import load_dataset
from streaming.base import MDSWriter
from torch.utils.data import DataLoader
from tqdm import tqdm

"""
Example Usage:
python convert.py --local_mds_dir ./textcaps/mds/
"""

def extract_commandline_flags():
    parser = ArgumentParser ()
    parser.add_argument("--local_mds_dir", type=str, help='Directory to store mds shards.')
    args = parser.parse_args()
    return args

# every dictionary is supposed to have same keys & different values
# hf stores images as list of dictionaries with the same keys
# one dictionary equals one image
def collate_fn(batch: List[Dict[str, Any]])-> Dict[str, List[Any]]:
    first_dict_keys = batch[0].keys()
    data = {k : [] for k in first_dict_keys}
    for b in batch:
        for k, v in b.items():
            data[k].append(v)
    return data

def main():
    args = extract_commandline_flags ()
    
    data_set = load_dataset ("HuggingFaceM4/TextCaps", split="train+validation")
    loader = DataLoader (data_set, batch_size=512, collate_fn=collate_fn)

    keys = ["height", "width", "jpg", "image_id", "org_captions"]
    samples = {k : [] for k in keys}

    # copy over to custom dictionary from batches in dataloader
    #for i, batch in tqdm (enumerate(loader)):
    #    samples["height"].extend(batch["image_height"])
    #    samples["width"].extend(batch["image_width"])
    #    samples["jpg"].extend(batch["image"])
    #    samples["image_id"].extend(batch["image_id"])
    #    samples["org_captions"].extend(batch["reference_strs"])

    print (f"Total{len(samples['jpg'])} samples in textcaps dataset")

    columns = {
        "height": "int32",
        "width": "int32",
        "jpg": "jpeg",
        "image_id": "str",
        "caption": "str"
    }

    writer = MDSWriter (out=args.local_mds_dir, columns=columns, compression=None, size_limit=256*(2**20), max_workers=16)

    for i, batch in tqdm(enumerate(loader)):
        for j in range (len(batch["image"])):
            try:
                mds_sample = {
                    "height" : batch["image_height"][j],
                    "width" : batch["image_width"][j],
                    "jpg": batch["image"][j],
                    "image_id": batch["image_id"][j],
                    # guess:0th caption is generated by LLaVa
                    "caption" : batch["reference_strs"][j][0]
                }
                writer.write(mds_sample)
                del mds_sample
            except Exception as e:
                print ( f"Error in writing sample:{j} batch:{i}: {e}")
    writer.finish()

if __name__ == "__main__":
    main()
